/**
 Predictor.swift
 TierkennerApp
 
 Bachelorthesis "Eine App zur Objekterkennung in Bildern mittels neuronaler Netze,
 trainiert mit dem ILSVRC-Datensatz"
 
 Hochschule Niederrhein
 
 Copyright (c) 2017 Martin Pietrowski
 
 Permission is hereby granted, free of charge, to any person obtaining a copy
 of this software and associated documentation files (the "Software"), to deal
 in the Software without restriction, including without limitation the rights
 to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 copies of the Software, and to permit persons to whom the Software is
 furnished to do so, subject to the following conditions:
 
 The above copyright notice and this permission notice shall be included in all
 copies or substantial portions of the Software.
 
 THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 SOFTWARE.
 **/
// TODO: Simpler machen, siehe screenshot

import UIKit
import CoreML
//import Vision

/**
 Uses a pre trained model for objectclassification.
 */
class Predictor: TierkennerProtocol {
    // For using trained tierkenner model.
    let model = Tierkenner()
    // Prediction with highest probability of last input.
    var classifications: TierkennerProtocol.Classifications?
    // Prediction with highest probability of last input.
    var lastHighestPrediction: (String, Float)?
    
    /**
     Classifies an object from a given picture.
     
     Scales UIImage to needed size (200*150) and converts it to CVPixelbuffer.
     This datatype is needed to use the autogenerated model.prediction() function.
     Saves results in an array of tuples. Finally, saves prediction with highest
     probability into lastHighestPrediction.
     
     - Input image: An image with an object to classify.
     
     - Returns: All labels of the model with a probability.
     */
    func predict(image: UIImage) -> TierkennerProtocol.Classifications {
        guard let scaledImage = resizeImage(image: image, toWidth: 200, toHeight: 150) else {
            fatalError("Error while resizing input image.")
        }
        
        guard let pixelBuffer = buffer(from: scaledImage) else {
            fatalError("Error while converting UIImage to CVPixelBuffer.")
        }
        
        guard let tierkennerOutput = try? model.prediction(image: pixelBuffer) else {
            fatalError("Error while objectclassification.")
        }
        
        guard let highestProbability = tierkennerOutput.probabilities[tierkennerOutput.classLabel] else {
            fatalError("No probability value in tierkennerOutput for classification \(tierkennerOutput.classLabel)")
        }
        
        self.classifications = TierkennerProtocol.Classifications()
        
        for classification in tierkennerOutput.probabilities {
            classifications?.append((classification.key, Float(classification.value)))
        }
        
        classifications = classifications!.sorted(by: {$0.confidence > $1.confidence})
        
        lastHighestPrediction = (tierkennerOutput.classLabel, Float(highestProbability))
        
        return classifications!
    }
    
    /**
     Returns prediction with the highest probability of the last image.
     */
    func getLastHighestPrediction() -> (label: String, probability: Float)? {
        return lastHighestPrediction
    }
    
    /**
     Resizes an UIImage to a given new width and height.
     
     Uses UIGraphicsContext as a canvas to draw image input on
     the canvas in a given size. Take the drawed image from the canvas
     to return at the end.
     
     - Returns: Resized UIImage.
     */
    private func resizeImage(image: UIImage, toWidth newWidth: CGFloat, toHeight newHeight: CGFloat) -> UIImage? {
        UIGraphicsBeginImageContext(CGSize(width: newWidth, height: newHeight))
        image.draw(in: CGRect(x: 0, y: 0, width: newWidth, height: newHeight))
        
        let newImage = UIGraphicsGetImageFromCurrentImageContext()
        UIGraphicsEndImageContext()
        
        return newImage
    }
    
    
    /**
     Converts UIImage to CVPixelBuffer.
     
     Creates a CVPixelBuffer with the same size as image input. Sets Colorspace of CVPixelBuffer
     and draws finally input image picture into CVPixelBuffer.
     
     Source: https://www.hackingwithswift.com/whats-new-in-ios-11 "Machine learning and Vision"
     
     - Parameter image: UIImage to convert.
     
     - Returns: converted UIImage to CVPixelBuffer.
     */
    private func buffer(from image: UIImage) -> CVPixelBuffer? {
        let attrs = [kCVPixelBufferCGImageCompatibilityKey: kCFBooleanTrue, kCVPixelBufferCGBitmapContextCompatibilityKey: kCFBooleanTrue] as CFDictionary
        var pixelBuffer : CVPixelBuffer?
        let status = CVPixelBufferCreate(kCFAllocatorDefault, Int(image.size.width), Int(image.size.height), kCVPixelFormatType_32ARGB, attrs, &pixelBuffer)
        
        guard (status == kCVReturnSuccess) else {
            return nil
        }
        
        CVPixelBufferLockBaseAddress(pixelBuffer!, CVPixelBufferLockFlags(rawValue: 0))
        let pixelData = CVPixelBufferGetBaseAddress(pixelBuffer!)
        
        let rgbColorSpace = CGColorSpaceCreateDeviceRGB()
        let context = CGContext(data: pixelData, width: Int(image.size.width), height: Int(image.size.height), bitsPerComponent: 8, bytesPerRow: CVPixelBufferGetBytesPerRow(pixelBuffer!), space: rgbColorSpace, bitmapInfo: CGImageAlphaInfo.noneSkipFirst.rawValue)
        
        context?.translateBy(x: 0, y: image.size.height)
        context?.scaleBy(x: 1.0, y: -1.0)
        
        UIGraphicsPushContext(context!)
        image.draw(in: CGRect(x: 0, y: 0, width: image.size.width, height: image.size.height))
        UIGraphicsPopContext()
        CVPixelBufferUnlockBaseAddress(pixelBuffer!, CVPixelBufferLockFlags(rawValue: 0))
        
        return pixelBuffer
    }
    
    /**
     Preprocesses a given UIImage. For now it simply converts an UIImage to a CIImage.
     
     - Input image: A UIImage to preprocess.
     */
    private func preprocess(image: UIImage) -> CIImage {
        guard let image = CIImage(image: image) else {
            fatalError("Failed converting UIImage to CIImage.")
        }
        
        return image
    }
    
    /*
     Returns label for a given key.
     
     - Parameter key: Key to get the label from.
     */
    func getLabel(key: String) -> String {
        switch key {
        case "bear":
            return "BÃ¤r ğŸ»"
        case "dog":
            return "Hund ğŸ•"
        case "elephant":
            return "Elefant ğŸ˜"
        case "frog":
            return "Frosch ğŸ¸"
        case "monkey":
            return "Affe ğŸµ"
        case "snake":
            return "Schlange ğŸ"
        case "swan":
            return "Schwan â¤ï¸"
        case "cat":
            return "Katze ğŸ±"
        case "eagle":
            return "Adler ğŸ¦…"
        case "fish":
            return "Fisch ğŸŸ"
        case "lizard":
            return "Echse ğŸ¦"
        case "horse":
            return "Pferd ğŸ"
        case "parrot":
            return "Papagai ğŸŒˆ"
        case "stork":
            return "Storch ğŸ‘¶"
        case "turtle":
            return "SchildkrÃ¶te ğŸ¢"
        default:
            return "Nichts"
        }
    }
}
