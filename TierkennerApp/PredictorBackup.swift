//
//  Predictor.swift
//  TierkennerApp
//
//  Created by Martin Pietrowski on 06.09.17.
//  Copyright Â© 2017 devpie. All rights reserved.
//
// TODO: Simpler machen, siehe screenshot

import UIKit
import CoreML
import Vision

/**
 Uses a pre trained model for objectclassification.
 */
class Predictor {
    // For using trained tierkenner model.
    let model = Tierkenner()
    // Prediction with highest probability of last input.
    var lastHighestPrediction: (String, Double)?
    
    /**
     Classifies an object from a given picture.
    
     Scales UIImage to needed size (200*150) and converts it to CVPixelbuffer.
     This datatype is needed to use the autogenerated model.prediction() function.
     Saves prediction with highest probability into lastHighestPrediction.
    
     - Input image: An image with an object to classify.
    
     - Returns: All labels of the model with a probability.
     */
    func predict(image: UIImage) -> [String: Double] {
        guard let scaledImage = resizeImage(image: image, newWidth: 200, newHeight: 150) else {
            fatalError("Error while resizing input image.")
        }
        
        guard let pixelBuffer = buffer(from: scaledImage) else {
            fatalError("Error while converting UIImage to CVPixelBuffer.")
        }
        
        guard let tierkennerOutput = try? model.prediction(image: pixelBuffer) else {
            fatalError("Error while objectclassification.")
        }
        
        guard let highestProbability = tierkennerOutput.probabilities[tierkennerOutput.classLabel] else {
            fatalError("No probability value in tierkennerOutput for classification \(tierkennerOutput.classLabel)")
        }
        
        lastHighestPrediction = (tierkennerOutput.classLabel, highestProbability)
        
        return tierkennerOutput.probabilities
    }
    
    /**
     Returns prediction with the highest probability of the last image.
     */
    func getLastHighestPrediction() -> (label: String, probability: Double)? {
        return lastHighestPrediction
    }
    
    /**
     Resizes an UIImage to a given new width and height.
     
     Uses UIGraphicsContext as a canvas to draw image input on
     the canvas in a given size. Take the drawed image from the canvas
     to return at the end.
     
     - Returns: Resized UIImage.
     */
    private func resizeImage(image: UIImage, newWidth: CGFloat, newHeight: CGFloat) -> UIImage? {
        UIGraphicsBeginImageContext(CGSize(width: newWidth, height: newHeight))
        image.draw(in: CGRect(x: 0, y: 0, width: newWidth, height: newHeight))
        
        let newImage = UIGraphicsGetImageFromCurrentImageContext()
        UIGraphicsEndImageContext()
        
        return newImage
    }
    
    
    /**
     
     */
    private func buffer(from image: UIImage) -> CVPixelBuffer? {
        let attrs = [kCVPixelBufferCGImageCompatibilityKey: kCFBooleanTrue, kCVPixelBufferCGBitmapContextCompatibilityKey: kCFBooleanTrue] as CFDictionary
        var pixelBuffer : CVPixelBuffer?
        let status = CVPixelBufferCreate(kCFAllocatorDefault, Int(image.size.width), Int(image.size.height), kCVPixelFormatType_32ARGB, attrs, &pixelBuffer)
        guard (status == kCVReturnSuccess) else {
            return nil
        }
        
        CVPixelBufferLockBaseAddress(pixelBuffer!, CVPixelBufferLockFlags(rawValue: 0))
        let pixelData = CVPixelBufferGetBaseAddress(pixelBuffer!)
        
        let rgbColorSpace = CGColorSpaceCreateDeviceRGB()
        let context = CGContext(data: pixelData, width: Int(image.size.width), height: Int(image.size.height), bitsPerComponent: 8, bytesPerRow: CVPixelBufferGetBytesPerRow(pixelBuffer!), space: rgbColorSpace, bitmapInfo: CGImageAlphaInfo.noneSkipFirst.rawValue)
        
        context?.translateBy(x: 0, y: image.size.height)
        context?.scaleBy(x: 1.0, y: -1.0)
        
        UIGraphicsPushContext(context!)
        image.draw(in: CGRect(x: 0, y: 0, width: image.size.width, height: image.size.height))
        UIGraphicsPopContext()
        CVPixelBufferUnlockBaseAddress(pixelBuffer!, CVPixelBufferLockFlags(rawValue: 0))
        
        return pixelBuffer
    }
    
    /**
     Preprocesses a given UIImage. For now it simply converts an UIImage to a CIImage.
     
     - Input image: A UIImage to preprocess.
     */
    private func preprocess(image: UIImage) -> CIImage {
        guard let image = CIImage(image: image) else {
            fatalError("Failed converting UIImage to CIImage.")
        }
        
        return image
    }
    
    /*
     Returns label for a given key.
     
     - Parameter key: Key to get the label from.
     */
    func getLabel(key: String) -> String {
        switch key {
        case "bear":
            return "BÃ¤r ðŸ»"
        case "dog":
            return "Hund ðŸ•"
        case "elephant":
            return "Elefant ðŸ˜"
        case "frog":
            return "Frosch ðŸ¸"
        case "monkey":
            return "Affe ðŸµ"
        case "snake":
            return "Schlange ðŸ"
        case "swan":
            return "Schwan â¤ï¸"
        case "cat":
            return "Katze ðŸ±"
        case "eagle":
            return "Adler ðŸ¦…"
        case "fish":
            return "Fisch ðŸŸ"
        case "horse":
            return "Pferd ðŸŽ"
        case "parrot":
            return "Papagai ðŸŒˆ"
        case "stork":
            return "Storch ðŸ‘¶"
        case "turtle":
            return "SchildkrÃ¶te ðŸ¢"
        default:
            return "Nichts"
        }
    }
}



// OLD

//
///**
// Contains all labels of the model with a probability.
// */
//private var predictions: [(label: String, confidence: Float)]!
//
///**
// Classifies an object from a given picture.
//
// - Input image: An image with an object to classify.
//
// - Returns: All labels of the model with a probability.
// */
//func predict(image: UIImage) -> [(String, Float)] {
//    let correctedImage = preprocess(image: image)
//
//    let handler = VNImageRequestHandler(ciImage: correctedImage)
//    do {
//        try handler.perform([classificationRequest])
//    } catch {
//        print(error)
//    }
//
//    return predictions
//}
//
///**
// Loads the ML model "Tierkenner.mlmodel" through its generated class and creates a Vision request for it.
// */
//private lazy var classificationRequest: VNCoreMLRequest = {
//    do {
//        let model = try VNCoreMLModel(for: Tierkenner().model)
//        return VNCoreMLRequest(model: model, completionHandler: self.handleClassification)
//    } catch {
//        fatalError("can't load Vision ML model: \(error)")
//    }
//}()
//
///**
// Puts the result of the objectclassification in the predictions array.
//
// - Input request: The request to the model.
// - Input error: Error message, if an error appeared.
//
// - See also: predictions
// */
//private func handleClassification(request: VNRequest, error: Error?) {
//    guard let observations = request.results as? [TierkennerOutput] else {
//        fatalError("unexpected result type from VNCoreMLRequest")
//    }
//
//    predictions = [(label: String, confidence: Float)]()
//
//    var counter = 0
//    for observation in observations {
//        counter = counter + 1
//        print(counter)
//        for classification in observation.probabilities {
//            print(classification.key + ", " + String(classification.value))
//        }
//    }
//
//
//    //        for observation in observations {
//    //            predictions.append((observation.identifier, observation.confidence))
//    //        }
//}
//
////    private func fancyPrint(request: VNRequest) {
////        for result in request.results {
////            result.
////        }
////    }

